{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedGroupKFold, cross_validate, StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "\n",
    "# add path to classification analysis functions\n",
    "from mixed_sigmoid_normalisation import MixedSigmoidScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in SPI directionality info\n",
    "SPI_directionality_info = pd.read_csv(\"../feature_extraction/pyspi_SPI_info.csv\")\n",
    "\n",
    "# Load data paths\n",
    "pyspi_res_path = \"/Users/abry4213/data/Cogitate_Batch2/MEG_Data/derivatives/time_series_features\"\n",
    "pyspi_res_path_averaged = f\"{pyspi_res_path}/averaged_epochs\"\n",
    "pyspi_res_path_individual = f\"{pyspi_res_path}/individual_epochs\"\n",
    "\n",
    "classification_res_path_averaged = \"/Users/abry4213/data/Cogitate_Batch2/MEG_Data/derivatives/classification_results/across_participants\"\n",
    "classification_res_path_individual = \"/Users/abry4213/data/Cogitate_Batch2/MEG_Data/derivatives/classification_results/within_participants\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification within individual subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in pyspi results\n",
    "for participant_pyspi_res_file in os.listdir(pyspi_res_path_individual):\n",
    "    individual_subject_pyspi_res = pd.read_csv(f\"{pyspi_res_path_individual}/{participant_pyspi_res_file}\")\n",
    "\n",
    "    # Extract subject ID\n",
    "    subject_ID = participant_pyspi_res_file.split(\"_\")[0]\n",
    "\n",
    "    # Fix stimulus_type where False to 'false' \n",
    "    individual_subject_pyspi_res['stimulus_type'] = individual_subject_pyspi_res['stimulus_type'].replace(False, 'false')\n",
    "\n",
    "    # meta-ROI comparisons: GWNT --> CS, CS --> GNWT, IIT --> CS, CS --> IIT\n",
    "    meta_roi_comparisons = [(\"GNWT\", \"Category_Selective\"), (\"Category_Selective\", \"GNWT\"), (\"IIT\", \"Category_Selective\"), (\"Category_Selective\", \"IIT\")]\n",
    "\n",
    "    # Relevance type comparisons\n",
    "    relevance_type_comparisons = [\"Relevant non-target\", \"Irrelevant\"]\n",
    "\n",
    "    # Stimulus presentation comparisons\n",
    "    stimulus_presentation_comparisons = individual_subject_pyspi_res.stimulus_presentation.unique().tolist()\n",
    "\n",
    "    # Stimulus type comparisons\n",
    "    stimulus_types = individual_subject_pyspi_res.stimulus_type.unique().tolist()\n",
    "    stimulus_type_comparisons = list(itertools.combinations(stimulus_types, 2))\n",
    "\n",
    "    # All comparisons list\n",
    "    n_jobs = 1\n",
    "    comparing_between_stimulus_types_classification_results_list = []\n",
    "\n",
    "    for meta_roi_comparison in meta_roi_comparisons:\n",
    "        print(\"ROI Comparison:\" + str(meta_roi_comparison))\n",
    "        ROI_from, ROI_to = meta_roi_comparison\n",
    "        for relevance_type in relevance_type_comparisons:\n",
    "            print(\"Relevance type:\" + str(relevance_type))\n",
    "            for stimulus_presentation in stimulus_presentation_comparisons:\n",
    "                print(\"Stimulus presentation:\" + str(stimulus_presentation))\n",
    "                # Finally, we get to the final dataset\n",
    "                final_dataset_for_classification = individual_subject_pyspi_res.query(\"meta_ROI_from == @ROI_from & meta_ROI_to == @ROI_to & relevance_type == @relevance_type & stimulus_presentation == @stimulus_presentation\").reset_index(drop=True).drop(columns=['index'])\n",
    "\n",
    "                for SPI in final_dataset_for_classification.SPI.unique():\n",
    "\n",
    "                    # Extract this SPI\n",
    "                    this_SPI_data = final_dataset_for_classification.query(f\"SPI == '{SPI}'\")\n",
    "\n",
    "                    # Find overall number of rows\n",
    "                    num_rows = this_SPI_data.shape[0]\n",
    "\n",
    "                    # Extract SPI values\n",
    "                    this_column_data = this_SPI_data[\"value\"]\n",
    "\n",
    "                    # Find number of NaN in this column \n",
    "                    num_NaN = this_column_data.isna().sum()\n",
    "                    prop_NaN = num_NaN / num_rows\n",
    "\n",
    "                    # Find mode and SD\n",
    "                    column_mode_max = this_column_data.value_counts().max()\n",
    "                    column_SD = this_column_data.std()\n",
    "\n",
    "                    # If 0% < num_NaN < 10%, impute by the mean of each component\n",
    "                    if 0 < prop_NaN < 0.1:\n",
    "                        values_imputed = (this_column_data\n",
    "                                            .transform(lambda x: x.fillna(x.mean())))\n",
    "\n",
    "                        this_column_data = values_imputed\n",
    "                        print(f\"Imputing column values for {SPI}\")\n",
    "                        this_SPI_data[\"value\"] = this_column_data\n",
    "\n",
    "                    # If there are: \n",
    "                    # - more than 10% NaN values;\n",
    "                    # - more than 90% of the values are the same; OR\n",
    "                    # - the standard deviation is less than 1*10**(-10)\n",
    "                    # then remove the column\n",
    "                    if prop_NaN > 0.1 or column_mode_max / num_rows > 0.9 or column_SD < 1*10**(-10):\n",
    "                        print(f\"{SPI} has low SD: {column_SD}, and/or too many mode occurences: {column_mode_max} out of {num_rows}, and/or {100*prop_NaN}% NaN\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Start an empty list for the classification results\n",
    "                    SPI_combo_res_list = []\n",
    "                \n",
    "                    # Iterate over stimulus combos\n",
    "                    for this_combo in stimulus_type_comparisons:\n",
    "\n",
    "                        # Extract just GNWT/CS data first\n",
    "                        final_dataset_for_classification_this_combo = this_SPI_data.query(f\"stimulus_type in {this_combo}\")\n",
    "\n",
    "                        # Define classification model\n",
    "                        model = LogisticRegression(penalty='l1', C=1, solver='liblinear', random_state=127)\n",
    "                        pipe = Pipeline([('scaler', MixedSigmoidScaler(unit_variance=True)), \n",
    "                                                ('model', model)])\n",
    "\n",
    "                        # Fit classifier\n",
    "                        X = final_dataset_for_classification_this_combo.value.to_numpy().reshape(-1, 1)\n",
    "                        y = final_dataset_for_classification_this_combo.stimulus_type.to_numpy().reshape(-1, 1)\n",
    "\n",
    "                        stimulus_stratified_CV = StratifiedKFold(n_splits = 10, shuffle = True, random_state=127)\n",
    "\n",
    "                        this_classifier_res = cross_validate(pipe, X, y, cv=stimulus_stratified_CV, scoring=\"accuracy\", n_jobs=n_jobs, \n",
    "                                                                    return_estimator=False, return_train_score=False)[\"test_score\"].mean()\n",
    "                        \n",
    "                        this_SPI_combo_df = pd.DataFrame({\"SPI\": [SPI], \n",
    "                                                            \"meta_ROI_from\": [ROI_from],\n",
    "                                                            \"meta_ROI_to\": [ROI_to],\n",
    "                                                            \"relevance_type\": [relevance_type],\n",
    "                                                            \"stimulus_presentation\": [stimulus_presentation],\n",
    "                                                            \"stimulus_combo\": [this_combo], \n",
    "                                                            \"accuracy\": [this_classifier_res]})\n",
    "                        \n",
    "                        # Append to growing results list\n",
    "                        comparing_between_stimulus_types_classification_results_list.append(this_SPI_combo_df)\n",
    "\n",
    "    comparing_between_stimulus_types_classification_results = pd.concat(comparing_between_stimulus_types_classification_results_list).reset_index(drop=True)\n",
    "    comparing_between_stimulus_types_classification_results.to_csv(f\"{classification_res_path_individual}/{subject_ID}_comparing_between_stimulus_types_classification_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_between_stimulus_types_classification_results.to_csv(f\"{classification_res_path_individual}/{subject_ID}_comparing_between_stimulus_types_classification_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can ask how -- for each stimulus type -- each SPI distinguishes between task relevance vs. irrelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/z0683sns3tz7b_k0cbf8ft8w0000gq/T/ipykernel_93316/1934161159.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  this_SPI_data[\"meta_ROI_pair\"] = this_SPI_data.meta_ROI_from + \"_\" + this_SPI_data.meta_ROI_to\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# All comparisons list\n",
    "comparing_between_relevance_types_classification_results_list = []\n",
    "\n",
    "meta_roi_comparison = meta_roi_comparisons[0]\n",
    "ROI_from, ROI_to = meta_roi_comparison\n",
    "stimulus_type = stimulus_types[0]\n",
    "stimulus_presentation = stimulus_presentation_comparisons[0]\n",
    "SPI = \"anm\"\n",
    "\n",
    "# Finally, we get to the final dataset\n",
    "final_dataset_for_classification = all_pyspi_res.query(\"meta_ROI_from == @ROI_from & meta_ROI_to == @ROI_to & stimulus_type == @stimulus_type & stimulus == @stimulus_presentation & relevance_type in @relevance_type_comparisons\").reset_index(drop=True).drop(columns=['index'])\n",
    "\n",
    "\n",
    "# Extract this SPI\n",
    "this_SPI_data = final_dataset_for_classification.query(f\"SPI == '{SPI}'\")\n",
    "\n",
    "# Look up directionality\n",
    "this_SPI_directionality = SPI_directionality_info.query(f\"SPI == '{SPI}'\").Directionality.values[0]\n",
    "\n",
    "# Merge meta ROIs according to directionality\n",
    "if this_SPI_directionality == \"Directed\":\n",
    "    this_SPI_data[\"meta_ROI_pair\"] = this_SPI_data.meta_ROI_from + \"_\" + this_SPI_data.meta_ROI_to\n",
    "    this_SPI_data = this_SPI_data.drop([\"meta_ROI_from\", \"meta_ROI_to\"], axis=1)\n",
    "else:\n",
    "    this_SPI_data_sorted = [sorted(pair) for pair in this_SPI_data[[\"meta_ROI_from\", \"meta_ROI_to\"]].values.tolist()]\n",
    "    this_SPI_data['meta_ROI_pair'] = ['_'.join(string) for string in this_SPI_data_sorted]\n",
    "    this_SPI_data = (this_SPI_data\n",
    "                .drop([\"meta_ROI_from\", \"meta_ROI_to\"], axis=1)\n",
    "                .drop_duplicates(ignore_index=True, subset=['subject_ID', 'meta_ROI_pair', 'relevance_type', 'stimulus'])\n",
    "                )\n",
    "\n",
    "# Find overall number of rows\n",
    "num_rows = this_SPI_data.shape[0]\n",
    "\n",
    "# Extract SPI values\n",
    "this_column_data = this_SPI_data[\"value\"]\n",
    "\n",
    "# Find number of NaN in this column \n",
    "num_NaN = this_column_data.isna().sum()\n",
    "prop_NaN = num_NaN / num_rows\n",
    "\n",
    "# Find mode and SD\n",
    "column_mode_max = this_column_data.value_counts().max()\n",
    "column_SD = this_column_data.std()\n",
    "\n",
    "# If 0% < num_NaN < 10%, impute by the mean of each component\n",
    "if 0 < prop_NaN < 0.1:\n",
    "    values_imputed = (this_column_data\n",
    "                        .transform(lambda x: x.fillna(x.mean())))\n",
    "\n",
    "    this_column_data = values_imputed\n",
    "    print(f\"Imputing column values for {SPI}\")\n",
    "    this_SPI_data[\"value\"] = this_column_data\n",
    "\n",
    "# If there are: \n",
    "# - more than 10% NaN values;\n",
    "# - more than 90% of the values are the same; OR\n",
    "# - the standard deviation is less than 1*10**(-10)\n",
    "# then remove the column\n",
    "if prop_NaN > 0.1 or column_mode_max / num_rows > 0.9 or column_SD < 1*10**(-10):\n",
    "    print(f\"{SPI} has low SD: {column_SD}, and/or too many mode occurences: {column_mode_max} out of {num_rows}, and/or {100*prop_NaN}% NaN\")\n",
    "\n",
    "# Start an empty list for the classification results\n",
    "SPI_combo_res_list = []\n",
    "\n",
    "# Define classification model\n",
    "model = LogisticRegression(penalty='l1', C=1, solver='liblinear', random_state=127)\n",
    "pipe = Pipeline([('scaler', MixedSigmoidScaler(unit_variance=True)), \n",
    "                        ('model', model)])\n",
    "\n",
    "# Fit classifier\n",
    "X = this_SPI_data.value.to_numpy().reshape(-1, 1)\n",
    "y = this_SPI_data.relevance_type.to_numpy().reshape(-1, 1)\n",
    "groups = this_SPI_data.subject_ID.to_numpy().reshape(-1, 1)\n",
    "\n",
    "group_stratified_CV = StratifiedGroupKFold(n_splits = 10, shuffle = True, random_state=127)\n",
    "\n",
    "this_classifier_res = cross_validate(pipe, X, y, groups=groups, cv=group_stratified_CV, scoring=\"accuracy\", n_jobs=1, \n",
    "                                            return_estimator=False, return_train_score=False)[\"test_score\"].mean()\n",
    "\n",
    "this_SPI_relevance_results_df = pd.DataFrame({\"SPI\": [SPI], \n",
    "                                    \"meta_ROI_from\": [ROI_from],\n",
    "                                    \"meta_ROI_to\": [ROI_to],\n",
    "                                    \"stimulus_type\": [stimulus_type],\n",
    "                                    \"stimulus_presentation\": [stimulus_presentation],\n",
    "                                    \"comparison\": [\"Relevant non-target vs. Irrelevant\"], \n",
    "                                    \"accuracy\": [this_classifier_res]})\n",
    "\n",
    "# Append to growing results list\n",
    "comparing_between_stimulus_types_classification_results_list.append(this_SPI_relevance_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/abry4213/anaconda3/envs/annie_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "SPI = \"cohmag_multitaper_max_fs-1_fmin-0-25_fmax-0-5\"\n",
    "ROI_from = \"IIT\" \n",
    "ROI_to = \"Category_Selective\"\n",
    "stimulus_type = \"object\"\n",
    "stimulus_presentation = \"on\"\n",
    "\n",
    "# Extract this SPI\n",
    "this_SPI_data = final_dataset_for_classification.query(f\"SPI == '{SPI}'\")\n",
    "\n",
    "# Find overall number of rows\n",
    "num_rows = this_SPI_data.shape[0]\n",
    "\n",
    "# Extract SPI values\n",
    "this_column_data = this_SPI_data[\"value\"]\n",
    "\n",
    "# Find number of NaN in this column \n",
    "num_NaN = this_column_data.isna().sum()\n",
    "prop_NaN = num_NaN / num_rows\n",
    "\n",
    "# Find mode and SD\n",
    "column_mode_max = this_column_data.value_counts().max()\n",
    "column_SD = this_column_data.std()\n",
    "\n",
    "# If 0% < num_NaN < 10%, impute by the mean of each component\n",
    "if 0 < prop_NaN < 0.1:\n",
    "    values_imputed = (this_column_data\n",
    "                        .transform(lambda x: x.fillna(x.mean())))\n",
    "\n",
    "    this_column_data = values_imputed\n",
    "    print(f\"Imputing column values for {SPI}\")\n",
    "    this_SPI_data[\"value\"] = this_column_data\n",
    "\n",
    "# If there are: \n",
    "# - more than 10% NaN values;\n",
    "# - more than 90% of the values are the same; OR\n",
    "# - the standard deviation is less than 1*10**(-10)\n",
    "# then remove the column\n",
    "if prop_NaN > 0.1 or column_mode_max / num_rows > 0.9 or column_SD < 1*10**(-10):\n",
    "    print(f\"{SPI} has low SD: {column_SD}, and/or too many mode occurences: {column_mode_max} out of {num_rows}, and/or {100*prop_NaN}% NaN\")\n",
    "\n",
    "# Start an empty list for the classification results\n",
    "SPI_combo_res_list = []\n",
    "\n",
    "# Define classification model\n",
    "model = LogisticRegression(penalty='l1', C=1, solver='liblinear', random_state=127)\n",
    "pipe = Pipeline([('scaler', MixedSigmoidScaler(unit_variance=True)), \n",
    "                        ('model', model)])\n",
    "\n",
    "# Fit classifier\n",
    "X = this_SPI_data.value.to_numpy().reshape(-1, 1)\n",
    "y = this_SPI_data.relevance_type.to_numpy().reshape(-1, 1)\n",
    "groups = this_SPI_data.subject_ID.to_numpy().reshape(-1, 1)\n",
    "\n",
    "group_stratified_CV = StratifiedGroupKFold(n_splits = 10, shuffle = True, random_state=127)\n",
    "\n",
    "this_classifier_res = cross_validate(pipe, X, y, groups=groups, cv=group_stratified_CV, scoring=\"accuracy\", n_jobs=1, \n",
    "                                            return_estimator=False, return_train_score=False)[\"test_score\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47750000000000004"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_classifier_res.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path as op\n",
    "import os\n",
    "from pyspi.calculator import Calculator\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_root = \"/headnode1/abry4213/data/Cogitate_Batch2/MEG_Data/\"\n",
    "averaged_epochs_dir = op.join(bids_root, \"derivatives\", \"time_series_features/averaged_epochs\")\n",
    "individual_epochs_dir = op.join(bids_root, \"derivatives\", \"time_series_features/individual_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files in averaged_epochs_dir\n",
    "averaged_epochs_files = os.listdir(averaged_epochs_dir)\n",
    "\n",
    "# Find subject names in averaged_epochs_files\n",
    "averaged_epochs_subjects = [f.split(\"_\")[0] for f in averaged_epochs_files]\n",
    "\n",
    "# list files in individual_epochs_dir\n",
    "individual_epochs_files = os.listdir(individual_epochs_dir)\n",
    "\n",
    "# Find subject names in individual_epochs_files\n",
    "individual_epochs_subjects = [f.split(\"_\")[0] for f in individual_epochs_files]\n",
    "\n",
    "# Find subjects that are in individual_epochs_files but not in averaged_epochs_files\n",
    "missing_subjects = list(set(individual_epochs_subjects) - set(averaged_epochs_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = \"CB042\"\n",
    "region_option = \"hypothesis_driven\"\n",
    "visit_id=\"1\"\n",
    "record=\"run\"\n",
    "duration = '1000ms'\n",
    "\n",
    "# Time series output path for this subject\n",
    "time_series_path = op.join(bids_root, \"derivatives\", \"MEG_time_series\")\n",
    "output_feature_path = op.join(bids_root, \"derivatives\", \"time_series_features/averaged_epochs\")\n",
    "\n",
    "# Define ROI lookup table\n",
    "if region_option == \"hypothesis_driven\":\n",
    "    ROI_lookup = {\"proc-0\": \"Category_Selective\",\n",
    "                  \"proc-1\": \"GNWT\",\n",
    "                  \"proc-2\": \"IIT\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all the time-series files for this subject\n",
    "sample_TS_data_list = []\n",
    "\n",
    "sample_TS_data=pd.read_csv(f\"{time_series_path}/sub-{subject_id}_ses-{visit_id}_meg_{duration}_all_time_series.csv\")\n",
    "sample_TS_data['duration'] = sample_TS_data['duration'].str.replace('ms', '').astype(int)\n",
    "sample_TS_data['times'] = np.round(sample_TS_data['times']*1000)\n",
    "sample_TS_data['times'] = sample_TS_data['times'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for face, Relevant target, 1000, on\n",
      "Missing data for face, Relevant target, 1000, off\n"
     ]
    }
   ],
   "source": [
    "# Filter times >= 0\n",
    "sample_TS_data = sample_TS_data.query('times >= 0')\n",
    "\n",
    "# Assign stimulus as on if times < duration and off if times >= duration\n",
    "sample_TS_data['stimulus'] = np.where(sample_TS_data['times'] < sample_TS_data['duration'], 'on', 'off')\n",
    "\n",
    "# Create list of dataframes for each stimulus_type, relevance_type, duration, and frequency_band\n",
    "# One list for 'on' (while stimulus is being presented) and another for 'off' (after stimulus is no longer being presented)\n",
    "sample_TS_data_list = []\n",
    "for stimulus_type in sample_TS_data['stimulus_type'].unique():\n",
    "    for relevance_type in sample_TS_data['relevance_type'].unique():\n",
    "        for duration in sample_TS_data['duration'].unique():\n",
    "            for stimulus_presentation in ['on', 'off']:\n",
    "            # for duration in sample_TS_data['duration'].unique():\n",
    "                this_condition_data = sample_TS_data.query('stimulus_type == @stimulus_type and relevance_type == @relevance_type and duration == @duration and stimulus == @stimulus_presentation')\n",
    "                if this_condition_data.empty:\n",
    "                    print(f\"Missing data for {stimulus_type}, {relevance_type}, {duration}, {stimulus_presentation}\")\n",
    "                    continue\n",
    "                sample_TS_data_list.append(this_condition_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pyspi_for_df(subject_id, df, calc):\n",
    "        # Make deepcopy of calc \n",
    "        calc_copy = deepcopy(calc)\n",
    "\n",
    "        # Pivot so that the columns are meta_ROI and the rows are data\n",
    "        df_wide = (df.filter(items=['times', 'Category_Selective', 'GNWT', 'IIT'])\n",
    "                     .melt(id_vars='times', var_name='meta_ROI', value_name='data')\n",
    "                     .reset_index()\n",
    "                     .pivot(index='meta_ROI', columns='times', values='data'))\n",
    "\n",
    "        # Convert to numpy array\n",
    "        TS_array = df_wide.to_numpy()\n",
    "\n",
    "        # Load data \n",
    "        calc_copy.load_dataset(TS_array)\n",
    "        calc_copy.compute()\n",
    "\n",
    "        SPI_res = deepcopy(calc_copy.table)\n",
    "\n",
    "        # Iterate over each SPI\n",
    "        SPI_res.columns = SPI_res.columns.to_flat_index()\n",
    "\n",
    "        SPI_res = SPI_res.rename(columns='__'.join).assign(meta_ROI_from = lambda x: x.index)\n",
    "        SPI_res_long = SPI_res.melt(id_vars='meta_ROI_from', var_name='SPI__meta_ROI_to', value_name='value')\n",
    "\n",
    "        SPI_res_long[\"SPI\"] = SPI_res_long[\"SPI__meta_ROI_to\"].str.split(\"__\").str[0]\n",
    "        SPI_res_long[\"meta_ROI_to\"] = SPI_res_long[\"SPI__meta_ROI_to\"].str.split(\"__\").str[1]\n",
    "\n",
    "        SPI_res_long = (SPI_res_long\n",
    "                        .drop(columns='SPI__meta_ROI_to')\n",
    "                        .query('meta_ROI_from != meta_ROI_to')\n",
    "                        .assign(meta_ROI_from = lambda x: x['meta_ROI_from'].map(ROI_lookup),\n",
    "                                meta_ROI_to = lambda x: x['meta_ROI_to'].map(ROI_lookup))\n",
    "                        .filter(items=['SPI', 'meta_ROI_from', 'meta_ROI_to', 'value'])\n",
    "                        .assign(stimulus_type = df['stimulus_type'].unique()[0],\n",
    "                                relevance_type = df['relevance_type'].unique()[0],\n",
    "                                duration = df['duration'].unique()[0],\n",
    "                                stimulus_presentation = df['stimulus'].unique()[0],\n",
    "                                subject_ID = subject_id)\n",
    "        )\n",
    "\n",
    "        return SPI_res_long\n",
    "# Initialise an empty list for the results\n",
    "pyspi_res_list = []\n",
    "\n",
    "# Initialise a base calculator\n",
    "calc = Calculator(subset='fast')\n",
    "\n",
    "# Run for data\n",
    "for dataframe in sample_TS_data_list:\n",
    "    dataframe_pyspi = run_pyspi_for_df(subject_id, dataframe, calc).assign(stimulus = \"on\")\n",
    "    pyspi_res_list.append(dataframe_pyspi)\n",
    "\n",
    "# Concatenate the results and save to a feather file\n",
    "all_pyspi_res = pd.concat(pyspi_res_list).reset_index() \n",
    "all_pyspi_res.to_csv(f\"{output_feature_path}/sub-{subject_id}_ses-{visit_id}_all_pyspi_results_{duration}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(averaged_epochs_dir):\n",
    "    file_string_replaced = file.replace(\".csv\", \"ms.csv\")\n",
    "    os.rename(f\"{averaged_epochs_dir}/{file}\", f\"{averaged_epochs_dir}/{file_string_replaced}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
